{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenetv2 for Testing - Take 2\n",
    "We are going to use a mobilnet to train a model and see how it does\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import DataGenerator, Plot_Val_Test\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 #for our model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV Data and creating Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train is: 160642 x 6 \n",
      "Shape of Val is 40198 x 6\n"
     ]
    }
   ],
   "source": [
    "CSV = pd.read_csv('../Data/train_extra.csv')\n",
    "\n",
    "# spling into train and validate\n",
    "Idx_Split = np.random.uniform(size = CSV.shape[0])\n",
    "CSV_Val = CSV[Idx_Split <= 0.2].copy()\n",
    "CSV_Train = CSV[Idx_Split > 0.2].copy()\n",
    "\n",
    "print(\"Shape of Train is: {} x {} \\nShape of Val is {} x {}\".format(CSV_Train.shape[0], \n",
    "                                                                    CSV_Train.shape[1],\n",
    "                                                                    CSV_Val.shape[0], \n",
    "                                                                    CSV_Val.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>Image_Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "      <td>../Data/Train/Train_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "      <td>../Data/Train/Train_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "      <td>../Data/Train/Train_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "      <td>../Data/Train/Train_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "      <td>../Data/Train/Train_4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme  \\\n",
       "0  Train_0             15                9                    5   ক্ট্রো   \n",
       "1  Train_1            159                0                    0        হ   \n",
       "2  Train_2             22                3                    5     খ্রী   \n",
       "3  Train_3             53                2                    2     র্টি   \n",
       "4  Train_4             71                9                    5     থ্রো   \n",
       "\n",
       "                   Image_Dir  \n",
       "0  ../Data/Train/Train_0.jpg  \n",
       "1  ../Data/Train/Train_1.jpg  \n",
       "2  ../Data/Train/Train_2.jpg  \n",
       "3  ../Data/Train/Train_3.jpg  \n",
       "4  ../Data/Train/Train_4.jpg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encodings is 168\n",
      "Number of Encodings is 168\n",
      "Target has 168 values,\n",
      "number of batches per epoch is 2510 x 2512\n"
     ]
    }
   ],
   "source": [
    "Gen_Train = DataGenerator(\n",
    "                csv_file = CSV_Train,\n",
    "                 y_var = 'grapheme_root', # 'consonant_diacritic',\n",
    "                 to_fit=True,\n",
    "                 batch_size=64,\n",
    "                 dim = (90,160),\n",
    "                 channels = 1,\n",
    "                 vertical_flip = 0,\n",
    "                 horizontal_flip = 0,\n",
    "                 rotate = (0.3,355), #PRob, max roatioan\n",
    "                 shear = (0.1,0.9), # prob, max_shear\n",
    "                 shuffle=True)\n",
    "\n",
    "Gen_Val = DataGenerator(\n",
    "                csv_file = CSV_Val,\n",
    "                 y_var = 'grapheme_root', # 'consonant_diacritic',\n",
    "                 to_fit=True,\n",
    "                 batch_size=16,\n",
    "                 dim = (90,160),\n",
    "                 channels = 1,\n",
    "                 vertical_flip = 0,\n",
    "                 horizontal_flip = 0,\n",
    "                 rotate = (0,0), #Prob, max roatioan\n",
    "                 shear = (0,0), # prob, max_shear\n",
    "                 shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Target has {} values,\\nnumber of batches per epoch is {} x {}\".format(Gen_Train.y.shape[1],\n",
    "                                                                                 len(Gen_Train),\n",
    "                                                                                 len(Gen_Val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "168*2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MNV2(input_shape: tuple,\n",
    "               alpha: int = 1,\n",
    "               weights: list = None,\n",
    "               dropout_per: float = 0.2,\n",
    "               target_size: int = 168,\n",
    "              learning_rate: float = 0.0002):\n",
    "    mobilenetV2 = MobileNetV2(\n",
    "                input_shape = input_shape,\n",
    "                alpha = alpha,\n",
    "                weights=weights,\n",
    "                include_top=False)\n",
    "    \n",
    "    #Making all layers in MobilenetV2 trainable!\n",
    "    for layer in mobilenetV2.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model = Sequential()\n",
    "    model.add(mobilenetV2)\n",
    "    model.add(layers.GlobalAveragePooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(512, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(256, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(target_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "  \n",
    "    return model\n",
    "\n",
    "\n",
    "def build_minst_big(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The forth Conco\n",
    "    layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "#    layers.Dense(256, activation='relu'),\n",
    "#    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "    \n",
    "def build_minst(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "\n",
    "\n",
    "def build_minst2(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "\n",
    "def build_springer(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002,\n",
    "                return_features = True):\n",
    "    \"\"\"Model based on this paper for character recognition\n",
    "    https://link.springer.com/article/10.1007/s11036-019-01243-5\n",
    "    \"\"\"\n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(128, (5,5), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(128, (5,5), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The Forth Layer\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    # drop out layer\n",
    "    layers.Dropout(dropout_per),\n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return mnst_model\n",
    "def build_mini_minst(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(10, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(30, (3,3)),\n",
    "    layers.LeakyReLU(0.05),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    # drop out layer\n",
    "    layers.Dropout(dropout_per),\n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_90 (Model)  (None, 3, 5, 1280)        2257408   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 1024)              1311744   \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 168)               43176     \n",
      "=================================================================\n",
      "Total params: 4,268,456\n",
      "Trainable params: 4,234,344\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_MNV2(input_shape = (90,160,1), dropout_per = 0.2, target_size = 168)\n",
    "#model = #build_minst2(input_shape = (90,160,1), dropout_per = 0.3, target_size = 168, learning_rate = 0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2510/2510 [==============================] - 1220s 486ms/step - loss: 4.5431 - accuracy: 0.0410 - val_loss: 5.1148 - val_accuracy: 0.0276\n",
      "Epoch 2/10\n",
      "2510/2510 [==============================] - 1217s 485ms/step - loss: 3.6688 - accuracy: 0.1618 - val_loss: 5.0470 - val_accuracy: 0.0282\n",
      "Epoch 3/10\n",
      "2510/2510 [==============================] - 1222s 487ms/step - loss: 2.5965 - accuracy: 0.3707 - val_loss: 2.3109 - val_accuracy: 0.4331\n",
      "Epoch 4/10\n",
      "2510/2510 [==============================] - 1218s 485ms/step - loss: 2.0767 - accuracy: 0.4959 - val_loss: 1.2408 - val_accuracy: 0.6618\n",
      "Epoch 5/10\n",
      "2510/2510 [==============================] - 1223s 487ms/step - loss: 1.7749 - accuracy: 0.5646 - val_loss: 0.8649 - val_accuracy: 0.7700\n",
      "Epoch 6/10\n",
      "2510/2510 [==============================] - 1222s 487ms/step - loss: 1.5737 - accuracy: 0.6092 - val_loss: 0.7924 - val_accuracy: 0.7863\n",
      "Epoch 7/10\n",
      "2510/2510 [==============================] - 1220s 486ms/step - loss: 1.4038 - accuracy: 0.6476 - val_loss: 0.7277 - val_accuracy: 0.8025\n",
      "Epoch 8/10\n",
      "2510/2510 [==============================] - 1216s 485ms/step - loss: 1.2854 - accuracy: 0.6730 - val_loss: 0.9463 - val_accuracy: 0.7485\n",
      "Epoch 9/10\n",
      "2510/2510 [==============================] - 1217s 485ms/step - loss: 1.1703 - accuracy: 0.6994 - val_loss: 0.7190 - val_accuracy: 0.8048\n",
      "Epoch 10/10\n",
      "2510/2510 [==============================] - 1219s 486ms/step - loss: 1.0859 - accuracy: 0.7188 - val_loss: 0.6447 - val_accuracy: 0.8236\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "    Gen_Train,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data = Gen_Val,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot_Val_Test(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'History' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-8a8be360b4bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'History' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m53\u001b[0m\n\u001b[0;31m    plt.imshow(display_grid, aspect='auto', cmap='viridis')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = Model(inputs = model.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "#horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "#human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "#img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = cv2.imread('../Data/Train/Train_1.jpg', cv2.IMREAD_GRAYSCALE)  # this is a PIL image\n",
    "x = img.reshape(1,90,160,1) # Numpy array with shape (150, 150, 3)\n",
    "x = x / 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) > 0 :\n",
    "        print('nice')\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            # Postprocess the feature to make it visually palatable\n",
    "            #x = feature_map[0, :, :, i]\n",
    "            x = feature_map[0, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "        # Display the grid\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "     plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model23' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a7647bafd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# intermediate representations for all layers in the previous model after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msuccessive_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#visualization_model = Model(img_input, successive_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model23' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model23.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = Model(inputs = model23.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "#horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "#human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "#img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = cv2.imread('/home/beltain/Data/fmnist/img_0.jpg', cv2.IMREAD_GRAYSCALE)  # this is a PIL image\n",
    "x = img.reshape(1,28,28,1) # Numpy array with shape (150, 150, 3)\n",
    "x = x / 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model23.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) > 0 :\n",
    "        print('nice')\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            # Postprocess the feature to make it visually palatable\n",
    "            #x = feature_map[0, :, :, i]\n",
    "            x = feature_map[0, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "        # Display the grid\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
