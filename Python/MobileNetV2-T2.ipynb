{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobilenetv2 for Testing - Take 2\n",
    "We are going to use a mobilnet to train a model and see how it does\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "gpus=tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import DataGenerator, Plot_Val_Test\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2 #for our model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in CSV Data and creating Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Train is: 160513 x 6 \n",
      "Shape of Val is 40327 x 6\n"
     ]
    }
   ],
   "source": [
    "CSV = pd.read_csv('../Data/train_extra.csv')\n",
    "\n",
    "# spling into train and validate\n",
    "Idx_Split = np.random.uniform(size = CSV.shape[0])\n",
    "CSV_Val = CSV[Idx_Split <= 0.2].copy()\n",
    "CSV_Train = CSV[Idx_Split > 0.2].copy()\n",
    "\n",
    "print(\"Shape of Train is: {} x {} \\nShape of Val is {} x {}\".format(CSV_Train.shape[0], \n",
    "                                                                    CSV_Train.shape[1],\n",
    "                                                                    CSV_Val.shape[0], \n",
    "                                                                    CSV_Val.shape[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "      <th>Image_Dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "      <td>../Data/Train/Train_0.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "      <td>../Data/Train/Train_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "      <td>../Data/Train/Train_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "      <td>../Data/Train/Train_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "      <td>../Data/Train/Train_4.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme  \\\n",
       "0  Train_0             15                9                    5   ক্ট্রো   \n",
       "1  Train_1            159                0                    0        হ   \n",
       "2  Train_2             22                3                    5     খ্রী   \n",
       "3  Train_3             53                2                    2     র্টি   \n",
       "4  Train_4             71                9                    5     থ্রো   \n",
       "\n",
       "                   Image_Dir  \n",
       "0  ../Data/Train/Train_0.jpg  \n",
       "1  ../Data/Train/Train_1.jpg  \n",
       "2  ../Data/Train/Train_2.jpg  \n",
       "3  ../Data/Train/Train_3.jpg  \n",
       "4  ../Data/Train/Train_4.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Encodings is 168\n",
      "Number of Encodings is 168\n",
      "Target has 168 values,\n",
      "number of batches per epoch is 1254 x 2016\n"
     ]
    }
   ],
   "source": [
    "Gen_Train = DataGenerator(\n",
    "                csv_file = CSV_Train,\n",
    "                 y_var = 'grapheme_root', # 'consonant_diacritic',\n",
    "                 to_fit=True,\n",
    "                 batch_size=160,\n",
    "                 dim = (90,160),\n",
    "                 channels = 1,\n",
    "                 vertical_flip = 0,\n",
    "                 horizontal_flip = 0,\n",
    "                 rotate = (0.3,355), #PRob, max roatioan\n",
    "                 shear = (0.1,0.9), # prob, max_shear\n",
    "                 shuffle=True,\n",
    "                save_model_path = '../Data/Best_Model_eva.hdf5')\n",
    "\n",
    "Gen_Val = DataGenerator(\n",
    "                csv_file = CSV_Val,\n",
    "                 y_var = 'grapheme_root', # 'consonant_diacritic',\n",
    "                 to_fit=True,\n",
    "                 batch_size=20,\n",
    "                 dim = (90,160),\n",
    "                 channels = 1,\n",
    "                 vertical_flip = 0,\n",
    "                 horizontal_flip = 0,\n",
    "                 rotate = (0,0), #Prob, max roatioan\n",
    "                 shear = (0,0), # prob, max_shear\n",
    "                 shuffle=True)\n",
    "\n",
    "\n",
    "print(\"Target has {} values,\\nnumber of batches per epoch is {} x {}\".format(Gen_Train.y.shape[1],\n",
    "                                                                                 len(Gen_Train),\n",
    "                                                                                 len(Gen_Val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MNV2(input_shape: tuple,\n",
    "               alpha: int = 1,\n",
    "               weights: list = None,\n",
    "               dropout_per: float = 0.2,\n",
    "               target_size: int = 168,\n",
    "              learning_rate: float = 0.0002):\n",
    "    mobilenetV2 = MobileNetV2(\n",
    "                input_shape = input_shape,\n",
    "                alpha = alpha,\n",
    "                weights=weights,\n",
    "                include_top=False)\n",
    "\n",
    "    #Making all layers in MobilenetV2 trainable!\n",
    "    for layer in mobilenetV2.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(mobilenetV2)\n",
    "    model.add(layers.GlobalMaxPooling2D())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1024, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(512, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(256, activation = 'relu'))\n",
    "    model.add(layers.Dropout(dropout_per))\n",
    "    model.add(layers.Dense(target_size, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_minst_big(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The forth Conco\n",
    "    layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "#    layers.Dense(256, activation='relu'),\n",
    "#    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "    \n",
    "def build_minst(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.Conv2D(8, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "\n",
    "\n",
    "def build_minst2(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(16, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(dropout_per),\n",
    "        \n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model\n",
    "\n",
    "def build_springer(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002,\n",
    "                return_features = True):\n",
    "    \"\"\"Model based on this paper for character recognition\n",
    "    https://link.springer.com/article/10.1007/s11036-019-01243-5\n",
    "    \"\"\"\n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(128, (5,5), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(128, (5,5), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    layers.Conv2D(256, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # The Forth Layer\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    # drop out layer\n",
    "    layers.Dropout(dropout_per),\n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    \n",
    "    return mnst_model\n",
    "def build_mini_minst(input_shape,\n",
    "                dropout_per,\n",
    "               target_size,\n",
    "               learning_rate = 0.0002):\n",
    "    \n",
    "    mnst_model = Sequential([\n",
    "    # This is the first convolution\n",
    "    layers.Conv2D(20, (3,3), activation='relu', input_shape=input_shape),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    layers.Conv2D(10, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Third layer\n",
    "    layers.Conv2D(5, (3,3), activation = 'relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    layers.Flatten(),\n",
    "    # 512 neuron hidden layer\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    # drop out layer\n",
    "    layers.Dropout(dropout_per),\n",
    "    layers.Dense(target_size, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    mnst_model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizers.Adam(lr=learning_rate),\n",
    "        #optimizer = optimizers.RMSprop(learning_rate = learning_rate )    ,\n",
    "        metrics=['accuracy']\n",
    "        )\n",
    "    return mnst_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_90 (Model)  (None, 3, 5, 1280)        2257408   \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              1311744   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 168)               43176     \n",
      "=================================================================\n",
      "Total params: 4,268,456\n",
      "Trainable params: 4,234,344\n",
      "Non-trainable params: 34,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_MNV2(input_shape = (90,160,1), dropout_per = 0.2, target_size = 168, learning_rate =  0.002)\n",
    "#model = build_minst(input_shape = (90,160,1), dropout_per = 0.3, target_size = 168, learning_rate = 0.001)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1254 steps, validate for 2016 steps\n",
      "Epoch 1/20\n",
      "1254/1254 [==============================] - 241s 192ms/step - loss: 4.4834 - accuracy: 0.0440 - val_loss: 4.9020 - val_accuracy: 0.0260\n",
      "Epoch 2/20\n",
      "1254/1254 [==============================] - 228s 182ms/step - loss: 3.9942 - accuracy: 0.0851 - val_loss: 5.2746 - val_accuracy: 0.0254\n",
      "Epoch 3/20\n",
      "1254/1254 [==============================] - 228s 182ms/step - loss: 3.6479 - accuracy: 0.1429 - val_loss: 9.8175 - val_accuracy: 0.0645\n",
      "Epoch 4/20\n",
      "1254/1254 [==============================] - 236s 188ms/step - loss: 3.4813 - accuracy: 0.1798 - val_loss: 7.4680 - val_accuracy: 0.1033\n",
      "Epoch 5/20\n",
      "1254/1254 [==============================] - 228s 182ms/step - loss: 2.9643 - accuracy: 0.2800 - val_loss: 5.1799 - val_accuracy: 0.2500\n",
      "Epoch 6/20\n",
      "1254/1254 [==============================] - 228s 181ms/step - loss: 3.0130 - accuracy: 0.2815 - val_loss: 3.7448 - val_accuracy: 0.2595\n",
      "Epoch 7/20\n",
      "1254/1254 [==============================] - 235s 188ms/step - loss: 2.7930 - accuracy: 0.3295 - val_loss: 2.2564 - val_accuracy: 0.4616\n",
      "Epoch 8/20\n",
      "1254/1254 [==============================] - 228s 182ms/step - loss: 2.5063 - accuracy: 0.3991 - val_loss: 2.1404 - val_accuracy: 0.4892\n",
      "Epoch 9/20\n",
      "1254/1254 [==============================] - 227s 181ms/step - loss: 2.3562 - accuracy: 0.4372 - val_loss: 2.7500 - val_accuracy: 0.3974\n",
      "Epoch 10/20\n",
      "1254/1254 [==============================] - 236s 188ms/step - loss: 3.1324 - accuracy: 0.2895 - val_loss: 2.1057 - val_accuracy: 0.4635\n",
      "Epoch 11/20\n",
      "1254/1254 [==============================] - 228s 182ms/step - loss: 2.3571 - accuracy: 0.4409 - val_loss: 3.2625 - val_accuracy: 0.2996\n",
      "Epoch 12/20\n",
      " 258/1254 [=====>........................] - ETA: 2:46 - loss: 2.4283 - accuracy: 0.4251"
     ]
    }
   ],
   "source": [
    "\n",
    "#history = model.fit_generator(\n",
    "history = model.fit(\n",
    "    Gen_Train,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    workers=16,\n",
    "    validation_data = Gen_Val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Plot_Val_Test(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 53)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m53\u001b[0m\n\u001b[0;31m    plt.imshow(display_grid, aspect='auto', cmap='viridis')\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = Model(inputs = model.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "#horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "#human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "#img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = cv2.imread('../Data/Train/Train_1.jpg', cv2.IMREAD_GRAYSCALE)  # this is a PIL image\n",
    "x = img.reshape(1,90,160,1) # Numpy array with shape (150, 150, 3)\n",
    "x = x / 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) > 0 :\n",
    "        print('nice')\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            # Postprocess the feature to make it visually palatable\n",
    "            #x = feature_map[0, :, :, i]\n",
    "            x = feature_map[0, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "        # Display the grid\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "     plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model23' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a7647bafd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# intermediate representations for all layers in the previous model after\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# the first.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msuccessive_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#visualization_model = Model(img_input, successive_outputs)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvisualization_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel23\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuccessive_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model23' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "# Let's define a new Model that will take an image as input, and will output\n",
    "# intermediate representations for all layers in the previous model after\n",
    "# the first.\n",
    "successive_outputs = [layer.output for layer in model23.layers[1:]]\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = Model(inputs = model23.input, outputs = successive_outputs)\n",
    "# Let's prepare a random input image from the training set.\n",
    "#horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
    "#human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
    "#img_path = random.choice(horse_img_files + human_img_files)\n",
    "\n",
    "img = cv2.imread('/home/beltain/Data/fmnist/img_0.jpg', cv2.IMREAD_GRAYSCALE)  # this is a PIL image\n",
    "x = img.reshape(1,28,28,1) # Numpy array with shape (150, 150, 3)\n",
    "x = x / 255\n",
    "\n",
    "# Let's run our image through our network, thus obtaining all\n",
    "# intermediate representations for this image.\n",
    "successive_feature_maps = visualization_model.predict(x)\n",
    "\n",
    "# These are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model23.layers]\n",
    "\n",
    "# Now let's display our representations\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "    print(feature_map.shape)\n",
    "    if len(feature_map.shape) > 0 :\n",
    "        print('nice')\n",
    "        # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
    "        n_features = feature_map.shape[-1]  # number of features in feature map\n",
    "        # The feature map has shape (1, size, size, n_features)\n",
    "        size = feature_map.shape[1]\n",
    "        # We will tile our images in this matrix\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            # Postprocess the feature to make it visually palatable\n",
    "            #x = feature_map[0, :, :, i]\n",
    "            x = feature_map[0, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            # We'll tile each filter into this big horizontal grid\n",
    "        display_grid[:, i * size : (i + 1) * size] = x\n",
    "        # Display the grid\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
