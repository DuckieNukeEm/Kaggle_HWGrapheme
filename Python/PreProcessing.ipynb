{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "from shutil import rmtree\n",
    "import cv2 as cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set some paramaters:\n",
    "\n",
    " * Boarder_Cut: how many pixles to cut off of each edge of the image. Some of the images have noise lines that run through the edges, so we will chip it down using this  \n",
    " * Split_Level: THe Test/Train split  \n",
    " * Noise_Threshhold: Any pixle below this value will be set to zero  \n",
    " * Base_Dir: what is the root director of where the data is stores\n",
    " * Train_Dir: where is the training data being stored  \n",
    " * Test_Dir: where is the testing Diata being stores  \n",
    " * Final_Dir: where is the final test data being stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Boarder_Cut = 3\n",
    "Noise_Threshhold = 5\n",
    "Base_Dir = '../Data/'\n",
    "\n",
    "Train_Dir = Base_Dir + 'Train'\n",
    "Test_Dir = Base_Dir + 'Test'\n",
    "\n",
    "\n",
    "IMPORT_LIST = [Base_Dir + 'train_image_data_' + x + '.parquet' for x in ['0','1','2','3']]\n",
    "IMPORT_VAL_LIST = [Base_Dir + 'test_image_data_' + x + '.parquet' for x in ['0','1','2','3']]\n",
    "TRAIN_CSV = Base_Dir + 'train.csv'\n",
    "TEST_CSV = Base_Dir + 'test.csv'\n",
    "\n",
    "\n",
    "#Df = pd.read_parquet('../Data/train_image_data_3.parquet')\n",
    "#Df_csv = pd.read_csv(TRAIN_CSV)\n",
    "#2.48GB in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounding_box(img, Values = False):\n",
    "    ce = 0\n",
    "    re = 0\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "    \n",
    "    if Values:\n",
    "        return rmin, rmax, cmin, cmax\n",
    "    else:\n",
    "        if rmin == rmax:\n",
    "            rmin = 0,\n",
    "            rmax = img.shape[0]\n",
    "        if cmin == cmax:\n",
    "            cmin = 0\n",
    "            cmax = img.shape[1]\n",
    "        return(img[rmin:rmax, cmin:cmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting and Making Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RR = pd.DataFrame(None)\n",
    "RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmtree(Train_Dir)\n",
    "rmtree(Test_Dir)\n",
    "os.mkdir(Train_Dir)\n",
    "os.mkdir(Test_Dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting the Train Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/train_image_data_0.parquet\n",
      "../Data/train_image_data_1.parquet\n",
      "../Data/train_image_data_2.parquet\n",
      "../Data/train_image_data_3.parquet\n"
     ]
    }
   ],
   "source": [
    "Train_csv_File = pd.DataFrame(None)\n",
    "\n",
    "for IL in IMPORT_LIST:\n",
    "    print(IL)\n",
    "    Df = pd.read_parquet(IL)\n",
    "    \n",
    "\n",
    "    # Extracting the raw values from the Data frame\n",
    "    Df_names = pd.DataFrame({'image_id':Df['image_id'].copy(),\n",
    "                           'Image_Dir': ''})\n",
    "    \n",
    "    Df_np = 255 - Df.iloc[:,1:].values.reshape(-1, 137,236).astype(np.uint8).copy()\n",
    "    \n",
    "    Df = None\n",
    "\n",
    "    #cropping size of the image\n",
    "    Df_np = Df_np[:,Boarder_Cut:-Boarder_Cut,Boarder_Cut:-Boarder_Cut]\n",
    "\n",
    "    #Reducing noise\n",
    "    Df_np[Df_np < Noise_Threshhold] = 0\n",
    "\n",
    "    for Idx in range(Df_np.shape[0]):\n",
    "        Img = bounding_box(Df_np[Idx,:,:])\n",
    "        Save_Dir = Train_Dir + '/' + Df_names.iloc[Idx,0] + '.jpg'\n",
    " \n",
    "        cv2.imwrite(Save_Dir, cv2.resize(Img, (160,90)))\n",
    "        Df_names.iloc[Idx,1] = Save_Dir\n",
    "    \n",
    "    if Train_csv_File.shape[0] == 0:\n",
    "        Train_csv_File = Df_names.copy()\n",
    "    else:\n",
    "        Train_csv_File = Train_csv_File.append(Df_names, ignore_index = True)\n",
    "    \n",
    "pd.merge(left = pd.read_csv(TRAIN_CSV), right = Train_csv_File, how = 'inner', on = 'image_id').to_csv(Base_Dir + 'train_extra.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now time to format the final Test Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Data/test_image_data_0.parquet\n",
      "../Data/test_image_data_1.parquet\n",
      "../Data/test_image_data_2.parquet\n",
      "../Data/test_image_data_3.parquet\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Test_CSV' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-9bc1e5d810cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mTest_csv_File\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_csv_File\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDf_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTest_CSV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTest_csv_File\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'image_id'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBase_Dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'test_extra.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Test_CSV' is not defined"
     ]
    }
   ],
   "source": [
    "Test_csv_File = pd.DataFrame(None)\n",
    "for IL in IMPORT_VAL_LIST:\n",
    "    print(IL)\n",
    "    Df = pd.read_parquet(IL)\n",
    "    \n",
    "\n",
    "    # Extracting the raw values from the Data frame\n",
    "    Df_names = pd.DataFrame({'image_id':Df['image_id'].copy(),\n",
    "                           'Image_Dir': ''})\n",
    "    \n",
    "    Df_np = 255 - Df.iloc[:,1:].values.reshape(-1, 137,236).astype(np.uint8).copy()\n",
    "    \n",
    "    Df = None\n",
    "\n",
    "    #cropping size of the image\n",
    "    Df_np = Df_np[:,Boarder_Cut:-Boarder_Cut,Boarder_Cut:-Boarder_Cut]\n",
    "\n",
    "    #Reducing noise\n",
    "    Df_np[Df_np < Noise_Threshhold] = 0\n",
    "\n",
    "    for Idx in range(Df_np.shape[0]):\n",
    "        Img = bounding_box(Df_np[Idx,:,:])\n",
    "        Save_Dir = Train_Dir + '/' + Df_names.iloc[Idx,0] + '.jpg'\n",
    " \n",
    "        cv2.imwrite(Save_Dir, cv2.resize(Img, (160,90)))\n",
    "        Df_names.iloc[Idx,1] = Save_Dir\n",
    "    \n",
    "    if Test_csv_File.shape[0] == 0:\n",
    "        Test_csv_File = Df_names.copy()\n",
    "    else:\n",
    "        Test_csv_File = Test_csv_File.append(Df_names, ignore_index = True)\n",
    "pd.merge(left = pd.read_csv(TEST_CSV), right = Test_csv_File, how = 'inner', on = 'image_id').to_csv(Base_Dir + 'test_extra.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = pd.read_csv(TEST_CSV), right = Test_csv_File, how = 'inner', on = 'image_id').to_csv(Base_Dir + 'test_extra.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_csv_File.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(TEST_CSV).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(left = pd.read_csv(TRAIN_CSV), right = Test_csv_File, how = 'inner', on = 'image_id').to_csv(Base_Dir + 'test_extra.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
